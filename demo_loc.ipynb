{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "from timeit import time\n",
    "\n",
    "# set config to initialize cudnn\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from stereo_reconstruction import structure\n",
    "from stereo_reconstruction import processor\n",
    "from stereo_reconstruction.features import match_images\n",
    "\n",
    "from yolo3_deepsort.yolo import YOLO\n",
    "from yolo3_deepsort.deep_sort.detection import Detection\n",
    "from yolo3_deepsort.deep_sort.tracker import Tracker\n",
    "from yolo3_deepsort.tools import generate_detections as gdet\n",
    "from yolo3_deepsort.tools.plot_utils import draw_one_box as draw_box\n",
    "from yolo3_deepsort.deep_sort.detection import Detection as ddet\n",
    "import yolo3_deepsort.tools.box_filter as box_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo3_deepsort/model_data/trained_weights_coco.h5 model, anchors, and classes loaded.\n",
      "WARNING:tensorflow:From /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/tools/generate_detections.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/tools/generate_detections.py:76: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/tools/generate_detections.py:77: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/tools/generate_detections.py:80: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create yolov3 detector\n",
    "score_thre = 0.5\n",
    "iou_thre = 0.3\n",
    "# yolo = YOLO(model_path = 'yolo3_deepsort/model_data/yolo_ori.h5',\n",
    "#             classes_path = 'yolo3_deepsort/model_data/coco_classes.txt',\n",
    "#             weights_only = True,\n",
    "#             score = score_thre,\n",
    "#             iou = iou_thre) # coco version\n",
    "yolo = YOLO(model_path = 'yolo3_deepsort/model_data/trained_weights_coco.h5',\n",
    "            classes_path = 'yolo3_deepsort/model_data/classes_name.txt',\n",
    "            weights_only = True,\n",
    "            score = score_thre,\n",
    "            iou = iou_thre) # our version\n",
    "\n",
    "# create feature encoder\n",
    "model_filename = 'yolo3_deepsort/model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename,batch_size=1)\n",
    "\n",
    "# create tracker\n",
    "max_distance = 0.3\n",
    "lambda0 = 1# SORT\n",
    "nn_budget = None\n",
    "tracker = Tracker(metric_mode=\"cosine\",max_cosine_distance=max_distance,\n",
    "                      lambda0 = lambda0,nn_budget=nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Tracking and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# video_path = r\"G:\\binocular_video\\20191022_022500_video.h265\"\n",
    "video_path = \"/media/yxhuang/database/binocular_video/20191022_022500_video.h265\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "w = int(cap.get(3))\n",
    "h = int(cap.get(4))\n",
    "fps = cap.get(5)\n",
    "thickness = 150\n",
    "COI = ['person','bicycle','car','motorcycle','bus','train','truck']\n",
    "\n",
    "write_flag = False\n",
    "if write_flag:\n",
    "    out = cv2.VideoWriter('result/road_test_COCO2.avi',cv2.VideoWriter_fourcc(*'XVID'), fps, (w//2,2*h))\n",
    "fontsize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    toi = time.time()\n",
    "    # read video\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret != True:\n",
    "        break# it's really really really important!!!\n",
    "        \n",
    "    frame_left = frame[:,:w//2,:]\n",
    "    frame_right = frame[:,w//2:,:]\n",
    "    img_left_pil = Image.fromarray(frame_left.copy()[...,::-1])\n",
    "    img_right_pil = Image.fromarray(frame_right.copy()[...,::-1])\n",
    "    \n",
    "    # detection\n",
    "    boxes,classes,scores = yolo.detect_image(img_left_pil)\n",
    "    \n",
    "    # filter boxes\n",
    "    boxes, classes, scores = box_filter.remove_edge(boxes,classes,scores,thickness,(w//2,h))\n",
    "    boxes, classes, scores = box_filter.select_classes(boxes,classes,scores,COI)\n",
    "    boxes, classes, scores = box_filter.non_max_suppression(boxes,classes,scores,iou_thre)\n",
    "\n",
    "    # encoder features\n",
    "    features = encoder(frame_left,boxes)\n",
    "    detections = [Detection(bbox,score,class_,feature)\n",
    "                    for bbox,score,class_,feature in zip(boxes,scores,classes,features)]\n",
    "#     detections = [Detection(bbox, score, class_)\n",
    "#                 for bbox,score,class_ in zip(boxes,scores,classes)]\n",
    "    \n",
    "    # call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    \n",
    "#     print(\"fps:%f\"%(1/(time.time()-toi)))\n",
    "    \n",
    "    # Visualize result++++++++++++++++++\n",
    "    img_left_draw = img_left_pil.copy()\n",
    "    img_right_draw = img_right_pil.copy()\n",
    "    for i,track in enumerate(tracker.tracks):\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue\n",
    "        \n",
    "        # track.to_tlbr() actually get ltrb && track.to_tlwh() actually get ltwh \n",
    "        bbox = track.to_tlbr()\n",
    "        _,_,bbox_matched = match_images(frame_left,frame_right,track.to_tlwh().astype(int),\n",
    "                                        offset=(-400,-40,0,40),method = cv2.TM_CCOEFF_NORMED)# match two image\n",
    "        \n",
    "        # property of the object\n",
    "        object_id = track.track_id\n",
    "        object_class = track.object_class\n",
    "        color = yolo.colors[yolo.class_names.index(object_class)]\n",
    "        # draw boxes\n",
    "        img_left_draw = draw_box(img_left_draw,bbox,object_id,object_class,color,fontsize)\n",
    "        img_right_draw = draw_box(img_right_draw,bbox_matched,object_id,object_class,color,fontsize)\n",
    "    \n",
    "#     print(\"fps:%f\"%(1/(time.time()-toi)))\n",
    "    \n",
    "    img_left_show = np.asarray(img_left_draw)\n",
    "    img_right_show = np.asarray(img_right_draw)\n",
    "    img_show = np.concatenate((img_left_show,img_right_show),axis = 0)\n",
    "    \n",
    "    if write_flag:\n",
    "        out.write(img_show[...,::-1])# save result\n",
    "    cv2.imshow('demo',cv2.resize(img_show[...,::-1],(int(w/2.5),int(h/1.5))))\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "if write_flag:\n",
    "    out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Parameters\n",
    "\n",
    "work_path = \"/media/yxhuang/database/binocular_video/\"\n",
    "intrinsic_path = work_path + r'stereo_intrinsic.yml'\n",
    "extrinsic_path = work_path + r'stereo_extrinsic.yml'\n",
    "# intrinsic_path = r'G:\\binocular_video\\stereo_intrinsic.yml'\n",
    "# extrinsic_path = r'G:\\binocular_video\\stereo_extrinsic.yml'\n",
    "intrinsic_paras = cv2.FileStorage(intrinsic_path, cv2.FILE_STORAGE_READ)\n",
    "extrinsic_paras = cv2.FileStorage(extrinsic_path, cv2.FILE_STORAGE_READ)\n",
    "P1 = extrinsic_paras.getNode('P1').mat()\n",
    "P2 = extrinsic_paras.getNode('P2').mat()\n",
    "R1 = extrinsic_paras.getNode('R1').mat()\n",
    "R2 = extrinsic_paras.getNode('R2').mat()\n",
    "T1 = np.zeros((3,1))\n",
    "T2 = extrinsic_paras.getNode('T').mat()\n",
    "M1 = intrinsic_paras.getNode('M1').mat()\n",
    "M2 = intrinsic_paras.getNode('M2').mat()\n",
    "D1 = intrinsic_paras.getNode('D1').mat()\n",
    "D2 = intrinsic_paras.getNode('D2').mat()\n",
    "# print(P1)\n",
    "# print(np.dot(M1,np.hstack((R1,T1))))\n",
    "# print(P2)\n",
    "# print(np.dot(M2,np.hstack((R2,T2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Images\n",
    "\n",
    "img_left = cv2.imread(work_path+'img/3400_left.jpg')\n",
    "img_right = cv2.imread(work_path+'img/3400_right.jpg')\n",
    "\n",
    "img_left_pil = Image.fromarray(img_left.copy()[...,::-1])\n",
    "img_right_pil = Image.fromarray(img_right.copy()[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_1/convolution (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3650) ]]\n\t [[boolean_mask_4/GatherV2/_2859]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_1/convolution (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3650) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node conv2d_1/convolution:\n input_1 (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517)\t\n conv2d_1/kernel/read (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402)\n\nInput Source operations connected to node conv2d_1/convolution:\n input_1 (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517)\t\n conv2d_1/kernel/read (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402)\n\nOriginal stack trace for 'conv2d_1/convolution':\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-46612da1d78e>\", line 13, in <module>\n    iou = iou_thre) # our version\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo.py\", line 48, in __init__\n    self.boxes, self.scores, self.classes = self.generate()\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo.py\", line 73, in generate\n    self.yolo_model = yolo_body(image_input,num_anchors,num_classes)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/model.py\", line 72, in yolo_body\n    darknet = Model(inputs, darknet_body(inputs))\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/model.py\", line 48, in darknet_body\n    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/utils.py\", line 14, in <lambda>\n    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/utils.py\", line 14, in <lambda>\n    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/layers/convolutional.py\", line 171, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3650, in conv2d\n    data_format=tf_data_format)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 894, in convolution\n    name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 971, in convolution_internal\n    name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n\t [[boolean_mask_4/GatherV2/_2859]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c3c26a43b637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthickness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_left_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# detect object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# filter boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo.py\u001b[0m in \u001b[0;36mdetect_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_image_shape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             })\n\u001b[1;32m    128\u001b[0m         \u001b[0mreturn_boxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_1/convolution (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3650) ]]\n\t [[boolean_mask_4/GatherV2/_2859]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_1/convolution (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3650) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node conv2d_1/convolution:\n input_1 (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517)\t\n conv2d_1/kernel/read (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402)\n\nInput Source operations connected to node conv2d_1/convolution:\n input_1 (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517)\t\n conv2d_1/kernel/read (defined at /home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402)\n\nOriginal stack trace for 'conv2d_1/convolution':\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-46612da1d78e>\", line 13, in <module>\n    iou = iou_thre) # our version\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo.py\", line 48, in __init__\n    self.boxes, self.scores, self.classes = self.generate()\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo.py\", line 73, in generate\n    self.yolo_model = yolo_body(image_input,num_anchors,num_classes)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/model.py\", line 72, in yolo_body\n    darknet = Model(inputs, darknet_body(inputs))\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/model.py\", line 48, in darknet_body\n    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/utils.py\", line 14, in <lambda>\n    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n  File \"/media/yxhuang/doc/MyWorld/junote/ByicycleBehaviorAnalysis/yolo3_deepsort/yolo3/utils.py\", line 14, in <lambda>\n    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/layers/convolutional.py\", line 171, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3650, in conv2d\n    data_format=tf_data_format)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 894, in convolution\n    name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 971, in convolution_internal\n    name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/yxhuang/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Detection and Matching\n",
    "\n",
    "COI = ['person','bicycle','car','motorcycle','bus','train','truck']\n",
    "h_img,w_img,_ = img_left.shape\n",
    "thickness = 150\n",
    "boxes,classes,scores = yolo.detect_image(img_left_pil)# detect object\n",
    "\n",
    "# filter boxes\n",
    "boxes, classes, scores = box_filter.remove_edge(boxes,classes,scores,thickness,(w_img,h_img))\n",
    "boxes, classes, scores = box_filter.select_classes(boxes,classes,scores,COI)\n",
    "boxes, classes, scores = box_filter.non_max_suppression(boxes,classes,scores,iou_thre)\n",
    "\n",
    "# NMS\n",
    "# idx2 = box_filter.non_max_suppression_idx(boxes,0.5,scores)\n",
    "# boxes, classes, scores = box_filter.get_by_index(idx2,boxes, classes, scores)\n",
    "\n",
    "boxes_matched = []\n",
    "boxes = np.array(boxes)# easier to compute\n",
    "img_left_draw = img_left_pil.copy()\n",
    "img_right_draw = img_right_pil.copy()\n",
    "for i,box in enumerate(boxes):\n",
    "    ret,search_patch,box_matched = match_images(img_left,img_right,box,offset=(-400,-40,0,40),\n",
    "                                   method = cv2.TM_CCOEFF_NORMED)# match two image\n",
    "    boxes_matched.append(box_matched)\n",
    "#     search_patches.append(search_patch)\n",
    "#     rets.append(ret)\n",
    "    \n",
    "    object_id = '0'\n",
    "    object_class = classes[i]\n",
    "    color = yolo.colors[yolo.class_names.index(object_class)]\n",
    "    # draw boxes\n",
    "    box[2:] = box[2:] + box[:2]# ltwh 2 ltrb. Note boxes had been changed!!!!!\n",
    "    img_left_draw = draw_box(img_left_draw,box,object_id,object_class,color,20)\n",
    "    img_right_draw = draw_box(img_right_draw,box_matched,object_id,object_class,color,20)\n",
    "#     print(\"box_r\",box_matched)\n",
    "    \n",
    "boxes_matched = np.array(boxes_matched)\n",
    "\n",
    "img_left_show = np.asarray(img_left_draw)\n",
    "img_right_show = np.asarray(img_right_draw)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_left_show)\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_right_show)\n",
    "\n",
    "cv2.imshow('left',img_left_show[...,::-1])\n",
    "cv2.imshow('right',img_right_show[...,::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the center of boxes stand for object's location\n",
    "pts2D_1 = np.ones((3,len(boxes)),dtype='float')\n",
    "pts2D_2 = np.ones((3,len(boxes)),dtype='float')\n",
    "\n",
    "# boxes[:,2:] = boxes[:,2:] + boxes[:,:2]# ltwh 2 ltrb\n",
    "for i in range(len(boxes)):\n",
    "    pts2D_1[:2,i] = (boxes[i,:2] + boxes[i,2:])/2.\n",
    "    pts2D_2[:2,i] = (boxes_matched[i,:2] + boxes_matched[i,2:])/2.\n",
    "\n",
    "# triangulation\n",
    "pts3D = structure.linear_triangulation(pts2D_1,pts2D_2,P1,P2)\n",
    "# pts3D = structure.linear_triangulation(pts2D_1,pts2D_2,P2,P1)\n",
    "# X朝右，Y朝上，Z朝前\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot(pts3D[0], pts3D[1], pts3D[2], 'b.')\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('y axis')\n",
    "ax.set_zlabel('z axis')\n",
    "ax.view_init(elev=135, azim=90)\n",
    "plt.show()\n",
    "# print('2D1:')\n",
    "# print(pts2D_1)\n",
    "# print(\"2D2:\")\n",
    "# print(pts2D_2)\n",
    "# print(pts3D[:3,:])\n",
    "print(\"distance:\")\n",
    "print(np.sqrt(np.sum(pts3D[:3,:]**2,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23df45fc940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 俯视图\n",
    "plt.scatter(pts3D[0,:],pts3D[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.389px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
